在PyCharm的Run的环境编辑中的ENvironmen variables中设置CUDA_VISIBLE_DEVICES=1或者0，指定使用的GPU
这样tensorflow此时只会在指定的GPU上运行，但是仍然会占用所有GPU的显存
在tensorflow中定义session时作如下设置，该设置会启用最少的GPU显存来运行程序。 
"config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)
config.gpu_options.allow_growth = True
tf.add_to_collection('graph_config', config)或者session = tf.Session(config=config) ，之后再使用session
allow_soft_placement 设置为 True, 这样 tensorFlow 会自动选择一个存在并且支持的设备来运行 operation"
在tensorflow中定义session时作如下设置，该设置会强制程序只占用指定比例的GPU显存。
"config = tf.ConfigProto() 
config.gpu_options.per_process_gpu_memory_fraction = 0.4 # 占用GPU40%的显存 
session = tf.Session(config=config)"

"如果用了config = tf.ConfigProto()，config.gpu_options.allow_growth = True，tf.add_to_collection('graph_config', config)
就不能再用tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True,)，这样会把前面的设置覆盖"

"有的代码不能在GPU上跑，会报错，参照下面的代码
with tf.device('/gpu:1'):
    net = tflearn.input_data(shape=[None, 21])
    net = tflearn.fully_connected(net, 1000)
    net = tflearn.fully_connected(net, 1, activation='tanh')
    net = tflearn.regression(net)
    # Define model
with tf.device('/cpu:0'):
    model = tflearn.DNN(net)"
